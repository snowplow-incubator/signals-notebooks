{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch features using Signals\n",
    "\n",
    "This notebook creates a new feature view using the SDK that will be computed using batch processing using an auto-generated dbt project with the same name.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Please note:</b>\n",
    "Batch features as features that are computed in the warehouse. They typically span over 1 or more days which would not be possible to do in stream. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow of data\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    sp(Snowplow Pipeline)\n",
    "    stream[/Autogenerated dbt model/]\n",
    "    signals(Signals)\n",
    "\n",
    "    sp --> stream\n",
    "    stream --> signals\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowplow_signals import Signals\n",
    "\n",
    "sp_signals = Signals(api_url='https://0fcfdf97-6447-4208-8cd0-39f82befbd07.svc.snplow.net')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a new feature\n",
    "\n",
    "There are 4 main types of features that you may likely want to define: \n",
    "1. Actions that happened in the `last_x_number of days`\n",
    "\n",
    "2. events or properties that happened for the `first time`\n",
    "\n",
    "3. `last time `\n",
    "\n",
    "4. `overall aggregation`s. \n",
    "\n",
    "We have illustrated each of these 4 types with an example blocks below. \n",
    "\n",
    "1. `products_added_to_cart_feature_last_7_days`: This feature calculates the number of add to cart ecommerce events in the last 7 days (Please note how the period is noted -> period=\"P7D\").\n",
    "\n",
    "2. `total_product_price_clv`: This feature is calculated across the customer lifetime (period left as None)\n",
    "\n",
    "3. `first_mkt_source`: This feature takes the first page_view event and reads the mkt_source property for a specific entity (domain_userid)\n",
    "\n",
    "4. `last_device_class`: This feature takes the first page_view event and extracts and retrieves the yauaa deviceClass property for a specific entity (domain_userid)\n",
    "\n",
    "Each block creates a single feature definition including the logic how it should be calculated (its filters and aggregation).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowplow_signals import (\n",
    "    Feature,\n",
    "    FilterCombinator,\n",
    "    FilterCondition,\n",
    ")\n",
    "from datetime import timedelta\n",
    "\n",
    "products_added_to_cart_feature_last_7_days = Feature(\n",
    "    name=\"products_added_to_cart_last_7_days\",\n",
    "    dtype=\"STRING_LIST\",\n",
    "    events=[\n",
    "        \"iglu:com.snowplowanalytics.snowplow.ecommerce/snowplow_ecommerce_action/jsonschema/1-0-2\"\n",
    "    ],\n",
    "    type=\"unique_list\",\n",
    "    property=\"contexts_com_snowplowanalytics_snowplow_ecommerce_product_1[0].name\",\n",
    "    scope=\"user\",\n",
    "    filter=FilterCombinator(\n",
    "        combinator=\"and\",\n",
    "        condition=[\n",
    "            FilterCondition(\n",
    "                property=\"unstruct_event_com_snowplowanalytics_snowplow_ecommerce_snowplow_ecommerce_action_1:type\",\n",
    "                operator=\"equals\",\n",
    "                value=\"add_to_cart\",\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    period=timedelta(days=7),\n",
    ")\n",
    "\n",
    "total_product_price_clv = Feature(\n",
    "    name=\"total_product_price_clv\",\n",
    "    dtype=\"FLOAT\",\n",
    "    events=[\n",
    "        \"iglu:com.snowplowanalytics.snowplow.ecommerce/snowplow_ecommerce_action/jsonschema/1-0-2\"\n",
    "    ],\n",
    "    type=\"aggregation(sum)\",\n",
    "    property=\"contexts_com_snowplowanalytics_snowplow_ecommerce_product_1[0].price\",\n",
    "    filter=FilterCombinator(\n",
    "        combinator=\"and\",\n",
    "        condition=[\n",
    "            FilterCondition(\n",
    "                property=\"unstruct_event_com_snowplowanalytics_snowplow_ecommerce_snowplow_ecommerce_action_1:type\",\n",
    "                operator=\"equals\",\n",
    "                value=\"add_to_cart\"\n",
    "            )   \n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "first_mkt_source = Feature(\n",
    "    name=\"first_mkt_source\",\n",
    "    dtype=\"STRING\",\n",
    "    events=[\n",
    "        \"iglu:com.snowplowanalytics.snowplow/page_view/jsonschema/1-0-0\"\n",
    "    ],\n",
    "    type=\"first\",\n",
    "    property=\"mkt_source\",\n",
    ")\n",
    "\n",
    "last_device_class = Feature(\n",
    "    name=\"last_device_class\",\n",
    "    dtype=\"STRING\",\n",
    "    events=[\n",
    "        \"iglu:com.snowplowanalytics.snowplow/page_view/jsonschema/1-0-0\"\n",
    "    ],\n",
    "    type=\"last\",\n",
    "    property=\"contexts_nl_basjes_yauaa_context_1[0]:deviceClass\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now go ahead and rewrite the above example code block to fit your need and add as many features as you like that you want to be processed together in the same dbt project and ultimately one feature table.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Please note:</b>\n",
    "The name of the feature will be a column name in the warehouse, be mindful of the warehouse limitations (keep it descriptive but concise). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping the feature in a feature view\n",
    "\n",
    "All features need to be included in feature views that can be considered as \"tables\" of features which will be processed together in the warehouse using dbt in an incremental fashion to save costs. Feature views are immutable and versioned. \n",
    "\n",
    "Below you can see how you can create a feature view using the feature definitions provided earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowplow_signals import FeatureView, user_entity\n",
    "\n",
    "feature_view = FeatureView(\n",
    "    name=\"batch_ecommerce_features\",\n",
    "    version=1,\n",
    "    entities=[\n",
    "        user_entity,\n",
    "    ],\n",
    "    features=[\n",
    "        products_added_to_cart_feature_last_7_days,\n",
    "        total_product_price_clv,\n",
    "        first_mkt_source,\n",
    "        last_device_class\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the feature view\n",
    "\n",
    "Execute the feature view from the atomic events table to verify that it works correctly. To keep the test simple the data will be filtered on the last hour only regardless of the period defined and the results will also be limited per 10 users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sp_signals.test(\n",
    "    feature_view=feature_view,\n",
    "    app_ids=[\"website\"],\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the feature view to Signals\n",
    "\n",
    "The following block pushes the feature view definition to the Signals API and makes it available for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_signals.apply([feature_view])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the dbt project \n",
    "\n",
    "Fetch and copy the API URL that you will need to generate the dbt project including the sql models that will incrementally update your features in your github repository. \n",
    "\n",
    "`filtered_events -> daily_aggregates -> features`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"URL for the feature view:\", f\"{sp_signals.api_client.api_url}/api/v1/registry/feature_views/{feature_view.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
